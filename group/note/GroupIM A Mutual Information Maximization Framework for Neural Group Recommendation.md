# GroupIM: A Mutual Information Maximization Framework for Neural Group Recommendation

**author**: Aravind Sankar

**organization**: UIUC, Visa Research

**conference**: SIGIR 2020

* [论文工作](#论文工作)

* [提出原因](#提出原因)

* [相关工作](#相关工作)

* [准备工作](#准备工作)

* [问题定义](##问题定义)


## 论文工作

**A Mutual Information Maximization Framework** **最大互信息框架**

我们的研究是针对短暂群组(**临时群组, ephemeral groups**)提出item recommendation的问题，这些群组由有限或没有历史交互的用户组成。现有的研究针对的是持久性群组(**persistent groups**) 局部活动的历史，而临时的群组缺乏历史交互。为了克服群组交互的==稀疏性(**sparsity**)==，我们提出了数据驱动的正则化策略来利用偏好协方差(**preference covariance**)挖掘在同一组的用户之间的差异，以及对每个群组来说用户偏好的相关性。

两个主要的工作：

* 首先，我们提出了一个**透明的推荐的框架(recommender architecture-agnostic[不可知的] framework)**——**GroupIM**，它可以集成任意的神经偏好编码器和聚合器(**neural preference encoders and aggregators**)对临时群组进行推荐。
* 其次，我们通过正则(**regularize**)用户组潜在空间来克服群组交互的稀疏性：最大化组和组成员表示之间的互信息；动态地通过上下文偏好加权，对信息丰富的成员的偏好进行优先排序。我们在几个真实数据集上的实验结果表明，显著的性能提高 (**31-62%**[**提升效果较大**]——**NDCG@20** )相对于最先进的组推荐技术。



## 提出原因

我们解决了向临时群组推荐item的问题，临时群组包括购买很少（或没有）项目的用户一起购买。这个问题无处不在，并且出现在各种家庭中。例如: 和陌生人一起吃饭，和新朋友一起看电影，以及参加社交活动。

我们用一个例子来说明关键问题：爱丽丝（喜欢墨西哥食物）带访客鲍勃（喜欢意大利菜）和她的同事一起吃午饭，他们要去哪里吃午饭？

这里有**三件事**要注意：

1. 这个群组是短暂(临时)的，因为没有历史交互信息。

2. 个人的偏好可能取决于其他群组成员。在这种情况下，这个团队可能会去一家精致的意大利餐厅(基于鲍勃访客的属性)。然而，当爱丽丝和其他朋友在一起时，他们可能会去墨西哥餐馆。

3. 群组由具有不同个人偏好的用户组成，因此群组推荐者需要认识到个人偏好。

之前的工作主要针对持久群组**(persistent group)**，指固定的、稳定的群组，成员们作为一个群组与许多items交互（例如，观看电影的家庭）。它们主要属于有两类：

* 忽略群组交互的启发式预定义聚合**（heuristic pre-defined aggregation）**（例如，最小痛苦(least misery)）
* 数据驱动的策略**（data-driven strategies）**，如概率模型和神经偏好聚合。

关键的缺点是——这些方法要么忽略了个人用户的活动，要么假设用户在不同的群组中遵循个人和集体偏好的可能性是相同的。缺乏表达能力来区分群组中个体偏好的作用，导致稀疏短暂群组的退化解。有几种方法利用社交网络、用户个性特征和人口统计等形式的外部信息进行群组决策。然而，辅助信息可能经常不可用。

我们在不重新排序任何附加信息的情况下训练强大的临时群组推荐模型。两点重要的发现：第一，虽然群组是临时的，但群组成员可能有丰富的个人交互历史，这可以缓解群组交互的稀疏性。其次，由于群组是临时的，训练交互很少，基本群组推荐模型需要可靠的指导来学习信息丰富（非退化）的群组表示，但指导需要数据驱动，而不是启发式。

为了克服群组互动的稀疏性，我们的关键技术的看法是以一种利用同一群组中的个体之间偏好协方差的方式，规范化用户和群组表征的潜在空间，并将用户个人偏好的上下文相关性与每个群组结合起来。

因此，我们提出了两种数据驱动的正则化策略。首先，我们对比地规范用户-群组的潜在空间，以捕捉**跨群组**的社会用户关联和差异。我们通过最大化群组和群组成员代表之间的互信息（MI）来实现这一点，这鼓励群组表征对**<u>共享的群组成员</u>**偏好进行编码，同时正则化用户表征以捕捉他们的社会关联。第二，我们在上下文中识别信息丰富的群组成员，并规范相应的群组表示，以反映他们的个人喜好。我们引入了一种新的正则化目标，该目标根据用户-组MI的比例，在上下文中加权每个组中用户的个人偏好。群自适应优先权排除了在对具有稀疏活动的短暂群进行静态正则化时出现的退化解。我们将主要贡献总结如下：

* 架构不可知框架：据我们所知，群组信息最大化（GroupIM）是第一个推荐者架构不可知的群组推荐框架。与之前设计定制偏好聚合器的工作不同，GroupIM可以集成任意神经偏好编码器和聚合器。我们用简单高效的聚合器（如meanpool）展示了最先进的结果，这些聚合器在我们的框架内进行了对比正则化。meanpool的有效性意味着在不损失模型表达能力的情况下大幅降低了推理成本。因此，GroupIM有助于直接增强基本神经推荐词。
* 群体适应性偏好优先排序：我们学习群体特定成员相关性的稳健估计。相比之下，之前的工作通过静态规则化结合了个人偏好。我们使用互信息动态学习用户和组表示，以捕获同一组中不同个体的偏好协方差；并优先考虑通过群体适应性偏好加权对高度相关成员的偏好；从而有效地克服了短暂群体的群体互动稀疏性。一项烧蚀研究证实了我们基于MI的正则化方法优于静态替代方法。
* 稳健的实验结果：我们的实验结果表明，在四个公开可用的数据集上，GroupIM的性能显著优于最先进的团体推荐者（**相对增益为31-62% NDCG@20，3-28% Recall@20**).很明显，GroupIM在以下方面获得了更大的收益：规模更大的群体；以及成员偏好不同的群体。



## 相关工作

**group recommendation：**这项工作可以根据组类型分为两类：持久性和临时性。持久性组有稳定的成员，他们一起有着丰富的活动历史，而临时性组则由一群在一起有很少交互的用户组成。一种常见的方法是将持久性组视为虚拟用户，从而可以直接应用个性化的推荐模型。然而，这种方法不能处理具有稀疏交互的临时群体。我们专注于向临时群体提出更具挑战性的情景建议。

之前的工作要么汇总每个成员的推荐结果（或项目分数），要么汇总每个成员对小组预测的偏好。它们分为两类：**分数（或后期）聚合和偏好（或早期）聚合**。流行的分数聚合策略包括痛苦最少、平均、满意度最高以及相关性和不一致性。然而，这些都是人为制定的启发法，忽略了现实世界中的群体互动。Baltrunas等人比较了不同的策略，得出结论：没有明确的赢家，它们的相对有效性取决于群体规模和群体一致性。

早期偏好聚合策略通过构建组合组成员的配置文件（原始项目历史）的组配置文件来生成推荐数据。最近的方法采用基于模型的视角来学习数据驱动的模型。概率方法通过考虑成员的个人偏好和相对影响，对群体生成过程进行建模，以区分他们对群体决策的贡献。然而，他们的一个关键弱点是假设用户在不同的群体中遵循个人和集体偏好的可能性相同。神经方法探索注意机制，通过子注意力网络学习数据驱动的偏好聚合器**MoSAN**模型群体互动；然而，MoSAN使用持久的组，而忽略用户的个人活动。**AGREE**利用注意力网络进行个人和团体互动的联合训练；然而，**应用于每个用户（基于个人活动）的正则化程度在不同组之间是相同的**，这导致在应用于具有稀疏活动的临时群组时出现**==退化解==**。

解决交互稀疏问题的**另一种方法是利用外部信息**，例如用户的社交网络、个性特征、人口统计和人际关系。**相比之下，我们的设置是保守的，不包括额外的辅助信息**：我们只知道用户和项目ID，以及项目隐式反馈。我们通过新颖的数据驱动正则化和训练策略来解决交互稀疏性问题。我们的目标是使广泛的神经组推荐者能够无缝地集成合适的偏好编码器和聚合器。

**互信息**：最近的神经MI[^ Mutual Information Neural Estimation. ICML 2018 ]估计方法利用**InfoMax原理**进行表征学习。他们通过**MI最大化目标**利用输入数据的结构（例如图像中的空间位置），以提高代表性质量。最近的进展利用自回归模型和聚集函数以及噪声对比损失函数来保持结构相关输入之间的MI。我们利用InfoMax原则来利用集团成员之间共享的偏好协方差结构。我们的方法的一个关键创新点是**==MI引导的加权==**，<u>以根据高度相关的成员的个人偏好调整群体嵌入。</u>

## 准备工作

### 问题定义

我们考虑隐式反馈设置（仅访问，没有显示评分(ratings)）与**用户集 $\mathcal{U}$ ，项目集 $\mathcal{I}$ ，群组集 $\mathcal{G}$ ，** $|\mathcal{U}|\times|\mathcal{I}|$ 的用户项目二元交互矩阵 $X_U$ ，和 $|\mathcal{G}|\times|\mathcal{I}|$ 群组项目二元交互矩阵$X_G$。我们将 $x_u,\ x_g$ 表示为 $X_U$ 和 $X_G$ 中用户 $u$ 和群组 $g$ 的对应行，其中 $|x_u|,\ |x_g|$ 表示各自的交互项目数。一个临时群组 $g \in \mathcal{G}$ 是由一组有着稀疏历史交互$|x_g|$ 的$|g|$ 个用户 $u^g=\{u_1^g,u_2^g,...,u_{|g|}^g\} \subset \mathcal{U}$ 组成 （意思是临时群组的交互是稀疏的，但群组中的每个用户的交互并不稀疏）。

**临时群组推荐**：我们在**最标准的**临时群组进行群组推荐评估，**最标准的意思**是这些临时群组在训练中是从未有过交互（就是临时群组没有交互行为）。在测试过程中，如果给定一个严格的临时组，我们的目标是生成一个与 $u^g$ 中的用户相关的项目集 $\mathcal{I}$ 的排名列表，即学习一个函数 $f_G \ : \ P(\mathcal{U}) \times \mathcal{I} \mapsto \mathbb{R}$ 将一个临时组和一个项目映射到一个相关性得分，其中 $P(\mathcal{U})$ 是 $\mathcal{U}$ 的幂集。

### 基础的神经群组推荐

一些神经群组推荐模型已经取得了令人印象深刻的结果[^ AGREE, 基于attention架构的模型]。尽管群组交互建模方面存在多样性，但我们注意到，最先进的神经方法都有一个共同的清晰的模型结构：我们提出了一个基础的群组推荐模型 **R**，它包括三个模块：**一个偏好编码器；一个偏好聚合器；以及一个联合用户和群组交互损失**。将这些神经群推荐模型统一在一个框架内，有助于深入分析它们在处理临时群体方面的缺点。

基础的群组推荐模型 **R** 首先使用偏好编码器 $f_{ENC}(\cdot)$ 从用户-项交互 $X_U$ 中计算**用户表征** $E \in \mathbb{R}^{|\mathcal{U}|\times D}$，然后应用神经偏好聚合器 $f_{AGG}(\cdot)$ 计算群组 **g** 的**群组表征 $e_g$。**最后，在群组 $X_G$ 和用户$X_U$的交互过程中对群组表征 $e_g$ 进行联合训练，实现群组推荐。

#### 用户偏好表征

用户嵌入 **E** 构成了他们个人偏好的隐式表征，如交互矩阵 $X_U$ 所示。由于隐式因子协同过滤方法采用多种策略（如矩阵分解、自动编码器等）来学习用户嵌入 **E**，我们定义了偏好编码器 $f_{ENC}\ : \ |\mathcal{U}|\times \mathbb{Z}_2^{|\mathcal{I}|} \mapsto \mathbb{R}^D$ 带有两个输入：用户u和关联二元个人偏好向量 $\mathcal{x}_u$。

![image-20220421163712365](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220421163712_image-20220421163712365.png)

我们可以通过定制的编码器，通过额外的输入来增强 $e_u$，包括上下文属性、item关系等

#### 群组偏好表征

偏好聚合模型对群组成员之间的交互进行建模，以计算临时群组 $g \in \mathcal{G}$ **聚合表征** $e_g \in \mathbb{R}^D$ .由于群组是没有固有排序的用户集，所以我们考虑集合上的置换不变函数（例如**求和**或**池化**操作）。具体地说，$f_{AGG}(\cdot)$ 是置换不变——对群成员嵌入 $\{e_{u_1},e_{u_2},...,e_{u_{|g|}}\}$ 的顺序不变。我们使用灵活的偏好聚合器$f_{AGG}(\cdot)$ 计算 $e_g$，如下所示：

![image-20220421165841900](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220421165842_image-20220421165841900.png)

#### 用户-群组联合损失

群组表征 $e_g$ 通过群组-项目 (group-item) 交互 $X_G$ 对群组损失 $L_G$ 进行训练。该框架支持不同的推荐目标，包括pairwise和pointwise 排序损失。在这里，我们使用多项式似然公式，因为它在基于用户的神经协同过滤中取得了令人印象深刻的结果[^ Variational autoencoders for collaborative filtering(VAE)  www 2018]。群组表征 $e_g$ 由一个 **FC** 进行转换，并通过 **softmax **进行归一化，以产生一个 $\mathcal{I}$ 上的 **概率向量** $\pi(e_g)$ 。损失测量归一化购买历史 $x_g /|x_g|$（$x_g$表示群组 $g$ 交互的items）和预测项目概率$\pi(e_g)$ 之间的**KL散度**，由下式给出：

![image-20220421185215885](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220421185216_image-20220421185215885.png)

接下来，我们定义用户损失 $L_U$，该 $L_U$ 通过用户-项交互 $X_U$ 正则化用户表征 $E$，从而促进与共享编码模型$f_{ENC}(\cdot)$和预测模型（$W_I$）层的联合训练。我们使用一种类似的基于多项式似然的形式，如下所示：

![image-20220421220257508](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220421220257_image-20220421220257508.png)

其中 $L_R$ 表示具有平衡超参数λ的基础推荐模型 **R** 的总体损失。**AGREE **在 $X_U$ 和 $X_G$ 上训练具有pairwise regression损失的注意力机制的聚合模型，而 **MoSAN** 在 $X_G$ 上训练具有**贝叶斯个性化排名损失**（其实就是pairewise loss）的子注意力聚合模型集合。因此，最先进的神经架构方法 **AGREE** 和 **MoSAN [^ Interact andDecide: Medley of Sub-Attention Networks for Effective Group Recommendation, SIGIR 2019]**是基本推荐模型 **R** 描述的框架的具体实例。

### 动机

为了解决临时群组的问题，我们专注独立于基础推荐模型 **R** 的**正则化策略**。随着神经网络方法的快速发展，我们设想未来增强用户表征和群组偏好聚合的神经架构。根据定义，由于临时群组很少一起购买物品，因此基础的推荐模型在群组交互中的训练数据常常不足。在这里，群组嵌入 $e_g$ 接收来自 $x_g$ 中稀疏交互项的反向传播信号，因此缺乏可靠估计每个成员角色的证据。为了解决群组交互稀疏问题，我们提出了两种独立于基本推荐机制的数据驱动正则化策略来生成个体和群组表征。

#### 对比表征学习(Contrastive Representation Learning)

我们注意到用户的偏好依赖于群组；并且群组中出现在一起的用户通常表现出共同的偏好（例如，共同的烹饪口味）。因此，群组活动揭示了群组内之间的差异（例如，密友与同事）和潜在的用户关联（例如，相似群组中的用户同时出现），当基础推荐模型 **R** 仅预测稀疏的群组交互时，这些差异并不明显。

我们将群组成员的偏好表征与具有相似item历史交互的非群组成员用户的偏好表征进行对比，以有效地正则化用户和群组表征的潜在空间。这有利于编码群组成员共享的潜在的可区别的特征，这些特征无法从XG中的有限交互项中辨别出来。

#### 群组自适应的偏好优先级

为了克服群组交互的稀疏性，我们批判性地指出，虽然群组交互是稀疏的，但群组成员的个体交互历史相对丰富。因此，我们主张有选择地利用群组成员的个人偏好来提高群组表征的质量。

基础的推荐模型 **R** 中的用户损失 $L_U$ (**equation (4)** )试图根据用户的个人活动来正则化用户嵌入 $E$ 。一个主要的缺点是，$L_U$ 迫使 $e_u$ 在所有包含 **user u **的群组中统一预测偏好 $x_u$。由于群组与物品的互动方式不同于个体成员，因此不准确地利用 $X_U$ 可能会适得其反。固定的正则化会形成过拟合或过度正则化的退化模型，这是因为在调整每个群组偏好方面缺乏灵活性。

为了克服群组交互的稀疏性，我们在情境中确定与群组高度相关的成员，并正则化群组表征，以反映他们的个人偏好。为了确定上下文关联性，我们为每个 **user u** 引入了特定于组的关联权重$w(u,g)$，其中 $w(\cdot)$ 是用户和群组表征的可学习的加权函数。这增强了推荐模型的表达能力，从而有效地缓解了群组交互稀疏带来的挑战。

在这一部分中，我们定义了临时群组推荐，并提出了一个基础的群组推荐模型体系结构，包括三个模块：**用户表征、群组偏好聚合和联合损失函数**。最后，我们就以下需求说明理由：<u>对比正则化用户-群组空间，以捕捉成员关联和群组差异；并学习特定于群组的权重  $w(u,g)$，以根据用户的个人偏好调整群组表征</u>

## GroupIM 框架

在本节中，我们首先说明互信息可以实现我们提出的两种正则化策略的**原因**，然后详细描述我们提出的框架 **GroupIM**。

#### 最大互信息 (Mutual Information Maximization)

我们通过一个例子来介绍我们的用户-群组互信息最大化方法。我们扩展了介绍性例子，以说明如何根据爱丽丝在两个不同群体中的交互来正则化她的潜在表征。先想想**Alice**，她先是和一位**访客Bob**一起去意大利餐馆吃午饭，后来又和她的**朋友Charlie**一起去墨西哥餐厅吃饭。

首先，由于群组环境（访客与朋友）的差异，Alice在两个群组中扮演不同的角色（即：朋友之间的影响力大于Bob）。因此，我们需要一个衡量标准来量化 **user u** 在群组 **g** 中的上下文信息。

其次，我们需要Alice的embedding来捕获Alice与访客Bob和朋友Charlie的关联，同时体现她的群组活动的变化。因此，不仅需要区分不同群组中Alice的角色，还需要计算使她在每个群组中的存在更加合乎逻辑的表征。

为了同时实现这两个目标，我们最大化用户组 **互信息 (MI)** 以正则化用户和群组表征的隐式空间，并根据其估计的互信息分数设置特定群组的相关权重 $w(u,g)$。用户-组互信息通过 **user u** 被包括在群组 **g** 中时的群组决策不确定性减少量来衡量 user u 对群组决策的上下文信息量。与**量化单调线性相关的关系度量不同**，互信息捕获了**协变随机变量**之间复杂的非线性统计关系。我们提出的MI最大化策略使我们能够实现双重动机：

* **改变隐式的表征几何结构**：最大化用户-组互信息推动群组嵌入 $e_g$  编码群组成员之间的偏好协方差，并正则化用户嵌入 $E$ 以捕获群组交互的社会关联。
* **特定群组的用户相关性**：通过用户-群组互信息量化$w(u,g)$，我们准确地捕捉到群组 **g ** 中**用户 u** 的信息量，从而指导群组进行自适应的个人偏好优先排序。

#### 用户-群组最大化互信息

neural MI估计已经证明了通过训练分类器 **D**（也称为鉴别器网络）将从联合分布中提取的正样本与从边缘分布中提取的负样本准确分离，从而使MI最大化的可行性。

我们在群组成员表征 $\{e_u \ : \ u \in u^g \}$ 和群组表征 $e_g$ 之间最大化用户-群组MI（**eq(1) 和 eq(2)** ）。我们训练了一个对比鉴别器网络 $D \ : \ \mathbb{R}^D \times \mathbb{R}^D \mapsto \mathbb{R}^+$，其中 $D(e_u,e_g)$ 表示分配给该 **用户-群组对** 的概率分数（属于群组 **g** 的用户得分更高）。**D** 的正样本 $(e_u,e_g)$是 $(u,g)$ 对的偏好表示使得 $u \in u^g$ ， 并且负样本是通过将 $e_g$ 与从**==负样本分布==** $P_{\mathcal{N}}(u|g)$ 【这也是为什么eq(5)中要对负样本对求期望，因为是按照一定分布采样负样本】中采样的非成员用户的表征配对而得出的。鉴别器 **D** 在联合分布**(正样本对)**和边缘分布**(负样本对)**的样本之间训练一个具有二元交叉熵（BCE）损失的噪声对比型目标函数，产生以下目标函数：

![image-20220422043232337](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422043232_image-20220422043232337.png)

$\alpha_g=|g|+ M_g$

$M_g$：对群组g负用户采用个数

$D_{ug}$：$D(e_u,e_g)$的简写

这个在$e_u,e_g$之间的目标最大化MI是基于在联合分布和边缘分布之间$Jensen-Shannon \ divergence$ ——**JS散度** [^ Deep Graph Infomax ICLR 2019]

我们采用 preference-biased 负采样分布 $P_{\mathcal{N}}(u|g)$ ，它为**购买**了群组项目 $x_g$ 的非成员用户分配了更高的概率。这些**严格的负样本** **(hard negative examples) ** 推动鉴别器通过与其他具有相似item历史的用户进行对比，来学习群组成员共享的隐式方面。我们将 $P_{\mathcal{N}}(u|g)$ 定义为：

![image-20220422050708065](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422050708_image-20220422050708065.png)

$\mathcal{I}(\cdot)$：指示函数(indicator function) , 括号里真取1，假取0

$\eta$：控制采样误差，我们取0.5

与随机负采样相比，我们的实验表明，preferenced-bias的负采样表现出更好的鉴别能力。

**当 $L_{MI}$ 与基础推荐模型损失 $L_R$（ eq(4) ）联合训练时，最大化用户组MI可提高编码器$f_{ENC}(\cdot)$ 和聚合器$f_{AGG}(\cdot)$ 计算的用户和群组表征的质量**。现在，我们介绍了克服固定正则化器LU限制的方法。

#### 上下文用户偏好加权

在本节中，我们描述了一种上下文权重策略，以确定相关群组成员的个人偏好并确定其优先级，从而克服群组交互稀疏性。我们通过特定群组的相关权重 $w(u,g)$ 来改变每个$x_u$在不同群组中引起的正则化程度，从而避免退化解。上下文权重解释了用户在不同临时群组中的参与情况，这些群组具有不同程度的共同兴趣。

通过最大化用户-群组MI，鉴别器 **D** 输出分数$D(e_u,e_g)$ ，量化每个 $(u,g)$ 对的上下文信息量（信息量高的用户的分数更高）。因此，我们为群组成员 $u\in u^g$ 设置了相关权重$w(u,g)$ 与$D(e_u,e_g)$成比例。我们没有在每个群组中用$x_u$正则化用户表征 **E**（eq (4) 中的$L_U$），而是直接用 $x_u$ 正则化群组表征 $e_g$，使其与每个群组成员u的 $D(e_u,e_g)$ 成比例。直接优化$e_g$（而不是$e_u$）会产生更有效的正则化，尤其是在稀疏的群组活动中。我们将上下文加权用户损失 $L_{UG}$ 定义为：

![image-20220422060048539](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422060048_image-20220422060048539.png)

我们的框架GroupIM的总体模型目标包括三个：$L_G$、$L_{UG}$和$L_{MI}$。GroupIM正则化隐式表征的计算通过以用户组MI最大化( $L_{MI}$ ) 的方式的 $f_{ENC}(\cdot)$  和$f_{AGG}(\cdot)$对比捕获群组成员关联；以及上下文MI引导的加权( $L_{UG}$ )来对个人偏好进行优先排序。 

#### 模型细节

##### 用户偏好编码  

两层MLP结构：

![image-20220422061535196](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422061535_image-20220422061535196.png)

激活函数：tanh

**预训练**  用eq(4)损失函数去训练$f_{ENC}(\cdot)$第一层的权值，将训练好的权值初始化第一层

##### 群组偏好聚合

* Maxpool

![image-20220422063333535](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422063333_image-20220422063333535.png)

* Meanpool 

 ![image-20220422063452268](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422063452_image-20220422063452268.png)

* Attention

![image-20220422063526789](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422063526_image-20220422063526789.png)

##### 鉴别器

![image-20220422065224421](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422065224_image-20220422065224421.png)

激活函数：sigmoid

##### 目标函数

![image-20220422065356560](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422065356_image-20220422065356560.png)

我们使用**交替优化**方式训练GroupIM。第一步，鉴别器**D**保持不变，同时在$L_G + \lambda L_{UG}$上优化群组推荐模型。第二步在$L_{MI}$上训练D，使得D的参数以及编码器$f_{ENC}(\cdot)$和聚合器$f_{AGG}(\cdot)$的参数梯度更新。[三者合为一体，其实就是一个加了正则项的损失函数]

![image-20220422070443466](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422070443_image-20220422070443466.png)



## Experiment

![image-20220422071340151](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422071340_image-20220422071340151.png)

首先，我们在大规模POI（兴趣点）上进行实验，从三个基于位置的社交网络中提取的推荐数据集。由于POI数据集不包含明确的群组交互，我们通过联合使用签到和社交网络信息来构建群组交互：**个人和社交网络中的朋友在15分钟内在同一POI签到**，构成了单一的群组交互，而POI的其余签到对应于个人交互。我们将群组推荐任务定义为向临时的用户群组推荐POI。对数据集进行预处理，以保留每个用户和项目有五次或五次以上的签到的用户和items。我们提供以下数据集描述：

* **Weeplaces**：WeePlaces是一种基于位置服务的可视化地图服务。Weeplaces已经与Gowalla和Facebook整合在一起，用户可以通过Foursquare、Gowalla和Facebook Places向好友显示自己的位置。

* **Yelp**：是另一个流行的LBSN ( Location-based Social Network,基于位置的社会网络 )平台。由于用户倾向于在不同的商业地点check-in，Yelp提供了来自分享自己经历的顾客的评论和评级，这既是出于个人目的，也是出于研究目的。

* **Gowalla**：Gowalla是一个LBSN平台，致力于位置签到。该平台成立于2007年，2012年被Facebook收购。Gowalla最初是一个移动应用程序，允许用户使用移动设备查看他们所访问的地点。

*  **Foursquare:**   foursquare成立于2009年，致力于在全球范围内收集和分发位置数据，为科技公司和品牌提供便利。数据集包含主要来自美国和东京的check-in数据。该数据集还包含LBSN中每个用户的所有好友列表。
* **Douban**:用户组织和参与社交活动，用户分组一起参加活动，项目与活动场地相对应。在预处理过程中，我们过滤掉少于10个交互的用户和场地 。

![image-20220422074900787](https://cdn.jsdelivr.net/gh/leelige/upic@main/uPic/20220422074900_image-20220422074900787.png)




